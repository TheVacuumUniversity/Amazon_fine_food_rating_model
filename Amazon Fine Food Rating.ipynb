{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#MongoDb\" data-toc-modified-id=\"MongoDb-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>MongoDb</a></span></li><li><span><a href=\"#Data-load-from-a-file\" data-toc-modified-id=\"Data-load-from-a-file-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data load from a file</a></span></li><li><span><a href=\"#Data-transformation\" data-toc-modified-id=\"Data-transformation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data transformation</a></span></li><li><span><a href=\"#Data-discovery\" data-toc-modified-id=\"Data-discovery-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Data discovery</a></span></li><li><span><a href=\"#Training-and-test-set\" data-toc-modified-id=\"Training-and-test-set-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training and test set</a></span></li><li><span><a href=\"#Featured-words\" data-toc-modified-id=\"Featured-words-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Featured words</a></span></li><li><span><a href=\"#NLTK-library---The-Naive-bayes-model\" data-toc-modified-id=\"NLTK-library---The-Naive-bayes-model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>NLTK library - The Naive bayes model</a></span></li><li><span><a href=\"#Accuracy---Confusion-matrix\" data-toc-modified-id=\"Accuracy---Confusion-matrix-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Accuracy - Confusion matrix</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusion</a></span></li><li><span><a href=\"#Next-steps\" data-toc-modified-id=\"Next-steps-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Next steps</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon fine food - rating prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have Amazon data about part of their product. In this section we are going to predict STAR rating according to sentences that a user wrote into summary and text field. See example https://www.amazon.com/Apple-Watch-Gold-Aluminum-Sport/dp/B075TDXYCS/ref=sr_1_17?s=electronics&ie=UTF8&qid=1540892072&sr=1-17#customerReviews \n",
    "\n",
    "\n",
    "Model selection\n",
    "\n",
    "We deceided to use Naive Bayes model as a good example of bayes classifiers. Naive Bayes classifiers mostly used in text classification (due to better result in multi class problems and independence rule) have higher success rate as compared to other algorithms. As a result, it is widely used in Spam filtering. It perform well in case of categorical input variables compared to numerical variable(s). The Naive Bayes classifier performs better compare to other models like logistic regression and you need less training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient #necessary to locally install mongodb \n",
    "from pymongo import DESCENDING\n",
    "import numpy as np #library with mathematical tools \n",
    "import matplotlib.pyplot as plt #for ploting graphs \n",
    "import pandas as pd #library for manage and import datasets\n",
    "import nltk #natural language processing library containing NaiveBayes\n",
    "from sklearn.model_selection import train_test_split #very useful when splitting a sample\n",
    "from nltk.metrics import ConfusionMatrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to upload data from a pandas dataframe to a local MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Auxiliary function - upload to Mongodb\n",
    "\n",
    "def upload_data_mongoDb(collection, data, delete_before_upload = True, silent_mode = False):\n",
    "    try:\n",
    "        if delete_before_upload == True: \n",
    "            # delete before insert\n",
    "            collection.delete_many({})\n",
    "            \n",
    "        # insert the dataframe to mongodb\n",
    "        collection.insert_many(data)\n",
    "\n",
    "        # dataframe_load = []\n",
    "        data = []\n",
    "        if silent_mode == False:\n",
    "            print('Dataframe uploaded to MongoDb')\n",
    "\n",
    "    except:\n",
    "        print('Error occured while uploading data to MongoDb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to localhost MongoDB database\n",
    "client = MongoClient()\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "# connect to an amazon_database\n",
    "db = client.amazon_database\n",
    "\n",
    "# Collections\n",
    "# connect to an amazon collection in the amazon database\n",
    "collection = db.amazon_collection\n",
    "\n",
    "# connect to an transformed collection in the amazon database \n",
    "transformed_collection = db.transformed_collection\n",
    "\n",
    "# connect to an word features collection in the amazon database \n",
    "wordfeatures_collection = db.wordfeatures_collection\n",
    "\n",
    "# connect to an training set collection in the amazon database \n",
    "train_set_collection = db.train_set_collection\n",
    "\n",
    "# connect to an training set collection in the amazon database - used in nltk model\n",
    "train_set_collection_nltk = db.train_set_collection_nltk\n",
    "\n",
    "# connect to an test set  collection in the amazon database \n",
    "test_set_collection = db.test_set_collection\n",
    "\n",
    "# connect to an test set  collection in the amazon database - used in nltk model\n",
    "test_set_collection_nltk = db.test_set_collection_nltk\n",
    "\n",
    "# connect to an featuring_temporary_collection in the amazon database \n",
    "featuring_temporary_collection = db.featuring_temporary_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "myColl = {}\n",
    "linecount = 1\n",
    "\n",
    "def makeDataFrame(dictionary):\n",
    "    global df\n",
    "    df=df.append(dictionary,ignore_index=True)      \n",
    "\n",
    "\n",
    "def loadData(filename, loadlines = np.inf):  \n",
    "    global myColl \n",
    "    global linecount\n",
    "    \n",
    "    # Open the file.\n",
    "    f = open(filename, \"r\")\n",
    "\n",
    "    \n",
    "    while(linecount <= loadlines):\n",
    "        try:\n",
    "            # Read a line.\n",
    "            line = f.readline()\n",
    "\n",
    "            # When readline returns an empty string, the file is fully read.\n",
    "            if line == \"\":\n",
    "                makeDataFrame(myColl)\n",
    "                myColl={}\n",
    "                break\n",
    "\n",
    "            # When a newline is returned, the line is empty.\n",
    "            if line == \"\\n\":\n",
    "                linecount = linecount + 1\n",
    "                makeDataFrame(myColl)\n",
    "                myColl={}\n",
    "                continue\n",
    "\n",
    "            # Print other lines.\n",
    "            stripped = line.strip().split(': ')\n",
    "            myColl[stripped[0]]=stripped[1]\n",
    "        except:\n",
    "            print(line)\n",
    "            print(linecount)\n",
    "            continue\n",
    "            \n",
    "    return df\n",
    "\n",
    "# number of loaded lines is limited \n",
    "dataframe = loadData(filename=\"foodscopy.txt\",loadlines = 500000)\n",
    "\n",
    "# number of loaded lines is unlimited - we load the whole sample\n",
    "# dataframe = loadData(filename=\"foodscopy.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>product/productId</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5bdfe521d95ae035681e56e3</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>1/1</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5bdfe521d95ae035681e56e4</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>0/0</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5bdfe521d95ae035681e56e5</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>1/1</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5bdfe521d95ae035681e56e6</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>3/3</td>\n",
       "      <td>Karl</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bdfe521d95ae035681e56e7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>0/0</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id product/productId review/helpfulness  \\\n",
       "0  5bdfe521d95ae035681e56e3        B001E4KFG0                1/1   \n",
       "1  5bdfe521d95ae035681e56e4        B00813GRG4                0/0   \n",
       "2  5bdfe521d95ae035681e56e5        B000LQOCH0                1/1   \n",
       "3  5bdfe521d95ae035681e56e6        B000UA0QIQ                3/3   \n",
       "4  5bdfe521d95ae035681e56e7        B006K2ZZ7K                0/0   \n",
       "\n",
       "                review/profileName review/score         review/summary  \\\n",
       "0                       delmartian          5.0  Good Quality Dog Food   \n",
       "1                           dll pa          1.0      Not as Advertised   \n",
       "2  Natalia Corres \"Natalia Corres\"          4.0  \"Delight\" says it all   \n",
       "3                             Karl          2.0         Cough Medicine   \n",
       "4    Michael D. Bigham \"M. Wassir\"          5.0            Great taffy   \n",
       "\n",
       "                                         review/text review/time  \\\n",
       "0  I have bought several of the Vitality canned d...  1303862400   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  1346976000   \n",
       "2  This is a confection that has been around a fe...  1219017600   \n",
       "3  If you are looking for the secret ingredient i...  1307923200   \n",
       "4  Great taffy at a great price.  There was a wid...  1350777600   \n",
       "\n",
       "    review/userId  \n",
       "0  A3SGXH7AUHU8GW  \n",
       "1  A1D87F6ZCVE5NK  \n",
       "2   ABXLMWJIXXAIN  \n",
       "3  A395BORC6FGVXV  \n",
       "4  A1UQRSCLF8GW1T  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Upload data from file to mongoDb\n",
    "upload_data_mongoDb(collection,dataframe.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a auxiliary function for following data transformation. First, we create a function that will remove meaningless word. We use nltk function pos_tag that assign a part of speech to every word. Then, we choose only relevant ones. Last, we can drop off columns that we are not going to use in this run such as productid or userid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove useless part of speech words such as 'the','a','this','that'. Leave only adjectives, nouns \n",
    "# See https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "def remove_wrong_words(wordlist):\n",
    "    wordlist2 = []\n",
    "    wordlist2 = nltk.pos_tag(nltk.word_tokenize(wordlist.replace('.',' ')))\n",
    "#     wordlist4 = [word for (word, pos) in wordlist3 if pos not in ['DT','EX','FW','RP','SYM','TO','IN','CC']] --\n",
    "    wordlist3 = [word for (word, pos) in wordlist2 if pos in ['JJ','JJR','JJS','RB','RBR','RBS','UH','NN','NNS','NNP','NNSP']]\n",
    "    return wordlist3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create new column 'good/bad' from 'review/score' column as well as summary_transformed column where we use remove_wrong_wrong function from previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "      <th>review/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>My cats LOVE this \"diet\" food better than thei...</td>\n",
       "      <td>One of my boys needed to lose some weight and ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Cats Are Not Fans of the New Food</td>\n",
       "      <td>My cats have been happily eating Felidae Plati...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lots of twizzlers, just what you expect.</td>\n",
       "      <td>My daughter loves twizzlers and this shipment ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>poor taste</td>\n",
       "      <td>I love eating them and they are good for watch...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>I am very satisfied with my Twizzler purchase....</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GREAT SWEET CANDY!</td>\n",
       "      <td>Twizzlers, Strawberry my childhood favorite ca...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Home delivered twizlers</td>\n",
       "      <td>Candy was delivered very fast and was purchase...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Always fresh</td>\n",
       "      <td>My husband is a Twizzlers addict.  We've bough...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TWIZZLERS</td>\n",
       "      <td>I bought these for my husband who is currently...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Delicious product!</td>\n",
       "      <td>I can remember buying this candy as a kid and ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Twizzlers</td>\n",
       "      <td>I love this candy.  After weight watchers I ha...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Please sell these in Mexico!!</td>\n",
       "      <td>I have lived out of the US for over 7 yrs now,...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Twizzlers - Strawberry</td>\n",
       "      <td>Product received is as advertised.&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nasty No flavor</td>\n",
       "      <td>The candy is just red , No flavor . Just  plan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Great Bargain for the Price</td>\n",
       "      <td>I was so glad Amazon carried these batteries. ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>YUMMY!</td>\n",
       "      <td>I got this for my Mum who is not diabetic but ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Best Hot Sauce in the World</td>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499970</th>\n",
       "      <td>Yum!</td>\n",
       "      <td>All of the Bob's Red Mill products are very go...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499971</th>\n",
       "      <td>Best Brand I've tasted. Fresh &amp; Nutty Flavor a...</td>\n",
       "      <td>I've tried a few brands of whole ground flax s...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499972</th>\n",
       "      <td>Omega 3s in a pleasant way</td>\n",
       "      <td>This goes in my cereal, in smoothies, or most ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499973</th>\n",
       "      <td>LOVE THIS STUFF!</td>\n",
       "      <td>I use this as an egg replacement in all my bak...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499974</th>\n",
       "      <td>Nice product</td>\n",
       "      <td>After reading the book \"Muscle foods\" I set ou...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499975</th>\n",
       "      <td>Heavy User -Quality Product</td>\n",
       "      <td>I am a heavy user of flax, this stuff tastes g...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499976</th>\n",
       "      <td>exactly what i wanted :)</td>\n",
       "      <td>i realized that i wasn't getting any omega-3 f...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499977</th>\n",
       "      <td>Good for you Flaxseed</td>\n",
       "      <td>I add Flaxseed to many dishes, however I use F...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499978</th>\n",
       "      <td>Organic Flaxseed Meal bought at Amazon</td>\n",
       "      <td>Organic flaxseed is an excellent product. Unfo...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499979</th>\n",
       "      <td>Disappointed</td>\n",
       "      <td>This was purchased on the recommendation of Dr...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499980</th>\n",
       "      <td>My Dog loves these!</td>\n",
       "      <td>My dog loves these and I love that they come i...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499981</th>\n",
       "      <td>These Spring rolls are made with a weird tasti...</td>\n",
       "      <td>I guess I was looking for steak and cheese spr...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499982</th>\n",
       "      <td>Dry and somewhat crumbly</td>\n",
       "      <td>I am a big fan of Coffaro's Biscotti but this ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499983</th>\n",
       "      <td>Caffaros Biscotti</td>\n",
       "      <td>The product is good but to expensive,especiall...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499984</th>\n",
       "      <td>The Lemon Vanilla Gluten-Free Biscotti are Add...</td>\n",
       "      <td>I picked up a pack locally and couldn't stop e...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499985</th>\n",
       "      <td>The best PB out there</td>\n",
       "      <td>This stuff is so good! I don't eat sugar, and ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499986</th>\n",
       "      <td>Makes a Great PBJ Sandwich!</td>\n",
       "      <td>So good...&lt;br /&gt;&lt;br /&gt;Smooth and creamy.  You'...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499987</th>\n",
       "      <td>the only peanut butter we eat!</td>\n",
       "      <td>My kids eat LOTS of peanut butter! After findi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499988</th>\n",
       "      <td>Great peanut butter, horrible price!</td>\n",
       "      <td>I love this peanut butter! Very well done and ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499989</th>\n",
       "      <td>Only peanut butter I eat</td>\n",
       "      <td>I stopped eating peanut butter for several yea...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>surprising</td>\n",
       "      <td>that they made a real NATURAL product..it only...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>My Favorite</td>\n",
       "      <td>After trying processed to ground peanuts and e...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499992</th>\n",
       "      <td>Very good and very healthy!</td>\n",
       "      <td>I love this peanut butter.  It tastes great an...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499993</th>\n",
       "      <td>Delicious PB</td>\n",
       "      <td>I dont have much to say that hasnt already bee...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499994</th>\n",
       "      <td>Best Tasting of any Peanutbutter</td>\n",
       "      <td>We have used Smucker's Natural (sometimes Orga...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>THOUGH I EAT THE UNSALTED VARIETY - 120 MG. OF...</td>\n",
       "      <td>CONTENTS - PEANUTS + 120 Mg. SALT - STILL 100%...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>lower the price</td>\n",
       "      <td>I can only eat sugar free PB and if Amazon low...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>Smuckers Natural Peanut Butter</td>\n",
       "      <td>Beware.&lt;br /&gt;&lt;br /&gt;This is a 16oz jar not 26 O...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>How to stir the best peanut butter on the market</td>\n",
       "      <td>This is by far the best peanut butter I've eve...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>Good Stuff</td>\n",
       "      <td>The jerky tastes good, the texture is good, ta...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review/summary  \\\n",
       "0                                   Good Quality Dog Food   \n",
       "1                                       Not as Advertised   \n",
       "2                                   \"Delight\" says it all   \n",
       "3                                          Cough Medicine   \n",
       "4                                             Great taffy   \n",
       "5                                              Nice Taffy   \n",
       "6           Great!  Just as good as the expensive brands!   \n",
       "7                                  Wonderful, tasty taffy   \n",
       "8                                              Yay Barley   \n",
       "9                                        Healthy Dog Food   \n",
       "10                        The Best Hot Sauce in the World   \n",
       "11      My cats LOVE this \"diet\" food better than thei...   \n",
       "12                   My Cats Are Not Fans of the New Food   \n",
       "13                                      fresh and greasy!   \n",
       "14                           Strawberry Twizzlers - Yummy   \n",
       "15               Lots of twizzlers, just what you expect.   \n",
       "16                                             poor taste   \n",
       "17                                               Love it!   \n",
       "18                                     GREAT SWEET CANDY!   \n",
       "19                                Home delivered twizlers   \n",
       "20                                           Always fresh   \n",
       "21                                              TWIZZLERS   \n",
       "22                                     Delicious product!   \n",
       "23                                              Twizzlers   \n",
       "24                          Please sell these in Mexico!!   \n",
       "25                                 Twizzlers - Strawberry   \n",
       "26                                        Nasty No flavor   \n",
       "27                            Great Bargain for the Price   \n",
       "28                                                 YUMMY!   \n",
       "29                        The Best Hot Sauce in the World   \n",
       "...                                                   ...   \n",
       "499970                                               Yum!   \n",
       "499971  Best Brand I've tasted. Fresh & Nutty Flavor a...   \n",
       "499972                         Omega 3s in a pleasant way   \n",
       "499973                                   LOVE THIS STUFF!   \n",
       "499974                                       Nice product   \n",
       "499975                        Heavy User -Quality Product   \n",
       "499976                           exactly what i wanted :)   \n",
       "499977                              Good for you Flaxseed   \n",
       "499978             Organic Flaxseed Meal bought at Amazon   \n",
       "499979                                       Disappointed   \n",
       "499980                                My Dog loves these!   \n",
       "499981  These Spring rolls are made with a weird tasti...   \n",
       "499982                           Dry and somewhat crumbly   \n",
       "499983                                  Caffaros Biscotti   \n",
       "499984  The Lemon Vanilla Gluten-Free Biscotti are Add...   \n",
       "499985                              The best PB out there   \n",
       "499986                        Makes a Great PBJ Sandwich!   \n",
       "499987                     the only peanut butter we eat!   \n",
       "499988               Great peanut butter, horrible price!   \n",
       "499989                           Only peanut butter I eat   \n",
       "499990                                         surprising   \n",
       "499991                                        My Favorite   \n",
       "499992                        Very good and very healthy!   \n",
       "499993                                       Delicious PB   \n",
       "499994                   Best Tasting of any Peanutbutter   \n",
       "499995  THOUGH I EAT THE UNSALTED VARIETY - 120 MG. OF...   \n",
       "499996                                    lower the price   \n",
       "499997                     Smuckers Natural Peanut Butter   \n",
       "499998   How to stir the best peanut butter on the market   \n",
       "499999                                         Good Stuff   \n",
       "\n",
       "                                              review/text review/score  \n",
       "0       I have bought several of the Vitality canned d...          5.0  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...          1.0  \n",
       "2       This is a confection that has been around a fe...          4.0  \n",
       "3       If you are looking for the secret ingredient i...          2.0  \n",
       "4       Great taffy at a great price.  There was a wid...          5.0  \n",
       "5       I got a wild hair for taffy and ordered this f...          4.0  \n",
       "6       This saltwater taffy had great flavors and was...          5.0  \n",
       "7       This taffy is so good.  It is very soft and ch...          5.0  \n",
       "8       Right now I'm mostly just sprouting this so my...          5.0  \n",
       "9       This is a very healthy dog food. Good for thei...          5.0  \n",
       "10      I don't know if it's the cactus or the tequila...          5.0  \n",
       "11      One of my boys needed to lose some weight and ...          5.0  \n",
       "12      My cats have been happily eating Felidae Plati...          1.0  \n",
       "13      good flavor! these came securely packed... the...          4.0  \n",
       "14      The Strawberry Twizzlers are my guilty pleasur...          5.0  \n",
       "15      My daughter loves twizzlers and this shipment ...          5.0  \n",
       "16      I love eating them and they are good for watch...          2.0  \n",
       "17      I am very satisfied with my Twizzler purchase....          5.0  \n",
       "18      Twizzlers, Strawberry my childhood favorite ca...          5.0  \n",
       "19      Candy was delivered very fast and was purchase...          5.0  \n",
       "20      My husband is a Twizzlers addict.  We've bough...          5.0  \n",
       "21      I bought these for my husband who is currently...          5.0  \n",
       "22      I can remember buying this candy as a kid and ...          5.0  \n",
       "23      I love this candy.  After weight watchers I ha...          5.0  \n",
       "24      I have lived out of the US for over 7 yrs now,...          5.0  \n",
       "25      Product received is as advertised.<br /><br />...          5.0  \n",
       "26      The candy is just red , No flavor . Just  plan...          1.0  \n",
       "27      I was so glad Amazon carried these batteries. ...          4.0  \n",
       "28      I got this for my Mum who is not diabetic but ...          5.0  \n",
       "29      I don't know if it's the cactus or the tequila...          5.0  \n",
       "...                                                   ...          ...  \n",
       "499970  All of the Bob's Red Mill products are very go...          5.0  \n",
       "499971  I've tried a few brands of whole ground flax s...          5.0  \n",
       "499972  This goes in my cereal, in smoothies, or most ...          5.0  \n",
       "499973  I use this as an egg replacement in all my bak...          5.0  \n",
       "499974  After reading the book \"Muscle foods\" I set ou...          5.0  \n",
       "499975  I am a heavy user of flax, this stuff tastes g...          5.0  \n",
       "499976  i realized that i wasn't getting any omega-3 f...          5.0  \n",
       "499977  I add Flaxseed to many dishes, however I use F...          5.0  \n",
       "499978  Organic flaxseed is an excellent product. Unfo...          3.0  \n",
       "499979  This was purchased on the recommendation of Dr...          3.0  \n",
       "499980  My dog loves these and I love that they come i...          4.0  \n",
       "499981  I guess I was looking for steak and cheese spr...          2.0  \n",
       "499982  I am a big fan of Coffaro's Biscotti but this ...          2.0  \n",
       "499983  The product is good but to expensive,especiall...          4.0  \n",
       "499984  I picked up a pack locally and couldn't stop e...          5.0  \n",
       "499985  This stuff is so good! I don't eat sugar, and ...          5.0  \n",
       "499986  So good...<br /><br />Smooth and creamy.  You'...          5.0  \n",
       "499987  My kids eat LOTS of peanut butter! After findi...          5.0  \n",
       "499988  I love this peanut butter! Very well done and ...          5.0  \n",
       "499989  I stopped eating peanut butter for several yea...          5.0  \n",
       "499990  that they made a real NATURAL product..it only...          5.0  \n",
       "499991  After trying processed to ground peanuts and e...          5.0  \n",
       "499992  I love this peanut butter.  It tastes great an...          5.0  \n",
       "499993  I dont have much to say that hasnt already bee...          5.0  \n",
       "499994  We have used Smucker's Natural (sometimes Orga...          5.0  \n",
       "499995  CONTENTS - PEANUTS + 120 Mg. SALT - STILL 100%...          5.0  \n",
       "499996  I can only eat sugar free PB and if Amazon low...          3.0  \n",
       "499997  Beware.<br /><br />This is a 16oz jar not 26 O...          1.0  \n",
       "499998  This is by far the best peanut butter I've eve...          5.0  \n",
       "499999  The jerky tastes good, the texture is good, ta...          5.0  \n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  load data from MongoDb\n",
    "data = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "# pick relevant columns\n",
    "data = data[['review/summary', 'review/text', 'review/score']]\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "data['dependent_variable']  = data['review/score'].apply(lambda x: 1 if float(x) >= 4 else 0)\n",
    "\n",
    "# remove non significant words\n",
    "data['independent_variable'] = data['review/summary'].apply(lambda x: remove_wrong_words(x.lower()))\n",
    "\n",
    "# Choose only independant variable and dependant variable\n",
    "data = data[['independent_variable', 'dependent_variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>independent_variable</th>\n",
       "      <th>dependent_variable</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good, quality, dog, food]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[not, advertised]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[delight]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[cough, medicine]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[great, taffy]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         independent_variable  dependent_variable  id\n",
       "0  [good, quality, dog, food]                   1   0\n",
       "1           [not, advertised]                   0   1\n",
       "2                   [delight]                   1   2\n",
       "3           [cough, medicine]                   0   3\n",
       "4              [great, taffy]                   1   4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['id'] = data.reset_index().index\n",
    "data.set_index('id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Upload transformed data to MongoDb\n",
    "upload_data_mongoDb(transformed_collection,data.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data discovery "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for counting good and bad ratings in order to see a ration in our sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_count(dataframe):\n",
    "    dataframe['dependent_variable'] = dataframe['dependent_variable'].apply(lambda x: int(x))\n",
    "    print ('Number of good ratings: ' + str(sum(dataframe['dependent_variable'])))\n",
    "    print ('Number of total ratings: ' + str(len(dataframe['dependent_variable'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good ratings: 389844\n",
      "Number of total ratings: 500000\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(list(transformed_collection.find({},{\"dependent_variable\"}))) \n",
    "good_count(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, Amazon is selling pretty quality products :) in Amazon fine food section due to high number of positive rating. This may cause a trouble in terms of an accuraccy. Let's keep it in mind and see how many bad rating we have in training sample as well as test sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(list(transformed_collection.find()))\n",
    "data = data.sample(n = 30000)\n",
    "data.set_index('id')\n",
    "\n",
    "# sklearn\n",
    "train_set, test_set = train_test_split(data, test_size=0.7, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set\n",
      "Number of good ratings: 7012\n",
      "Number of total ratings: 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('training_set')\n",
    "good_count(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_set\n",
      "Number of good ratings: 16326\n",
      "Number of total ratings: 21000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('test_set')\n",
    "good_count(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Upload training data to MongoDb\n",
    "upload_data_mongoDb(train_set_collection,train_set.to_dict('records'))\n",
    "train_set_collection.create_index([(\"id\", DESCENDING)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Upload test data to MongoDb\n",
    "upload_data_mongoDb(test_set_collection,test_set.to_dict('records'))\n",
    "test_set_collection.create_index([(\"id\", DESCENDING)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featured words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Naive Bayes we need to create featured words that will indicate good/bad. We want to use only the most common word used in our train sample. We call it 'wordfeatures'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick up only TOP most common word in our dataset and use them as featured words \n",
    "def wordFeatures(wordList,top):\n",
    "    forbidenwords = ['.','..','%',\"n't\",'amazon.com','dr.','mrs.','.but','mr.','tea..']\n",
    "    wordList = nltk.FreqDist(wordList)\n",
    "    wordList = wordList.most_common(top)\n",
    "    wordFeatures = [{'features':words} for words,counts in wordList if words not in forbidenwords]\n",
    "    return wordFeatures   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list with all word occured in the dataset. We call it features and we upload it to MongoDB into collection wordfeatures_collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList = []\n",
    "\n",
    "for row in train_set_collection.find({},{\"independent_variable\"}):\n",
    "    wordList.extend(row['independent_variable'])\n",
    "\n",
    "features = wordFeatures(wordList,10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Upload featured word to MongoDb\n",
    "upload_data_mongoDb(wordfeatures_collection,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK library - The Naive bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare new column independent_variable_naive_bayes into a format that is being used in nltk library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does words in a sentence contains in featured words \n",
    "def getFeatures(doc,featuredwords):\n",
    "    docWords = set(doc)\n",
    "    feat ={}\n",
    "    for word in featuredwords:\n",
    "        feat['contains(%s)' % word] = (word in docWords)\n",
    "    return feat\n",
    "\n",
    "def feature_dataset(collection, featuredwords):\n",
    "    data = []\n",
    "    featuring_temporary_collection.delete_many({})\n",
    "    \n",
    "    for i in range(0,500):\n",
    "        try:\n",
    "            # classsic ETL \n",
    "            number_of_lines = 1000\n",
    "            # load data\n",
    "            data = pd.DataFrame(list(collection.find({\"id\": {\"$gte\": i * number_of_lines , \"$lt\": (i+1)*number_of_lines}})))\n",
    "            # transform data\n",
    "            data['independent_variable_naive_bayes'] = data['independent_variable'].apply(lambda x: getFeatures(x,featuredwords))\n",
    "            # load data       \n",
    "            upload_data_mongoDb(featuring_temporary_collection, \n",
    "                                data.to_dict('records'), \n",
    "                                delete_before_upload = False, \n",
    "                                silent_mode = True)\n",
    "        except:\n",
    "            break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of featured words\n",
    "featuredwords = pd.DataFrame(list(wordfeatures_collection.find()))\n",
    "featuredwords = list(featuredwords.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training set for NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to Mongo\n",
    "feature_dataset(train_set_collection,featuredwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_prepared_NLTK = pd.DataFrame(list(featuring_temporary_collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>dependent_variable</th>\n",
       "      <th>id</th>\n",
       "      <th>independent_variable</th>\n",
       "      <th>independent_variable_naive_bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5be2d3d8d95ae0035cbb1644</td>\n",
       "      <td>5.0</td>\n",
       "      <td>977</td>\n",
       "      <td>[brews, excellent, cup, coffee, quickly, easily]</td>\n",
       "      <td>{'contains(great)': False, 'contains(good)': F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5be2d3d8d95ae0035cbb15f5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>898</td>\n",
       "      <td>[i, n't, smell]</td>\n",
       "      <td>{'contains(great)': False, 'contains(good)': F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5be2d3d8d95ae0035cbb15f0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>893</td>\n",
       "      <td>[strictly, best]</td>\n",
       "      <td>{'contains(great)': False, 'contains(good)': F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5be2d3d8d95ae0035cbb15ef</td>\n",
       "      <td>5.0</td>\n",
       "      <td>892</td>\n",
       "      <td>[fantastic, coffee, best, i, ever]</td>\n",
       "      <td>{'contains(great)': False, 'contains(good)': F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5be2d3d8d95ae0035cbb15de</td>\n",
       "      <td>1.0</td>\n",
       "      <td>875</td>\n",
       "      <td>[something]</td>\n",
       "      <td>{'contains(great)': False, 'contains(good)': F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  dependent_variable   id  \\\n",
       "0  5be2d3d8d95ae0035cbb1644                 5.0  977   \n",
       "1  5be2d3d8d95ae0035cbb15f5                 5.0  898   \n",
       "2  5be2d3d8d95ae0035cbb15f0                 5.0  893   \n",
       "3  5be2d3d8d95ae0035cbb15ef                 5.0  892   \n",
       "4  5be2d3d8d95ae0035cbb15de                 1.0  875   \n",
       "\n",
       "                               independent_variable  \\\n",
       "0  [brews, excellent, cup, coffee, quickly, easily]   \n",
       "1                                   [i, n't, smell]   \n",
       "2                                  [strictly, best]   \n",
       "3                [fantastic, coffee, best, i, ever]   \n",
       "4                                       [something]   \n",
       "\n",
       "                    independent_variable_naive_bayes  \n",
       "0  {'contains(great)': False, 'contains(good)': F...  \n",
       "1  {'contains(great)': False, 'contains(good)': F...  \n",
       "2  {'contains(great)': False, 'contains(good)': F...  \n",
       "3  {'contains(great)': False, 'contains(good)': F...  \n",
       "4  {'contains(great)': False, 'contains(good)': F...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_prepared_NLTK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_data_mongoDb(train_set_collection_nltk,training_set_prepared_NLTK.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training set for NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataset(test_set_collection,featuredwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_prepared_NLTK = pd.DataFrame(list(featuring_temporary_collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x32178800>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload to Mongo\n",
    "upload_data_mongoDb(test_set_collection_nltk,test_set_prepared_NLTK.to_dict('records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict with NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_nltk(collection):\n",
    "    data = []\n",
    "    dataset = []\n",
    "    \n",
    "    data = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "    for index, row in data[['independent_variable_naive_bayes', 'dependent_variable']].iterrows():\n",
    "          dataset.append((row[0], row[1]))\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = transform_data_for_nltk(train_set_collection_nltk)\n",
    "test_set = transform_data_for_nltk(test_set_collection_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8371904761904762\n"
     ]
    }
   ],
   "source": [
    "# create Naive Bayes classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Test accuracy\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Try your own words\n",
    "print(classifier.classify(getFeatures('great'.split(),featuredwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Try your own words\n",
    "print(classifier.classify(getFeatures('bad'.split(),featuredwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy - Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |     0     1 |\n",
      "--+-------------+\n",
      "0 | <2005> 2655 |\n",
      "1 |   764<15576>|\n",
      "--+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_set_pred = [classifier.classify(word) for (word, tag) in test_set]\n",
    "test_set_tag = [tag for (word, tag) in test_set]\n",
    "\n",
    "\n",
    "print(nltk.ConfusionMatrix(test_set_tag, test_set_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix depicts that 2655 cases were predicted as false positives (I.order error). If we would predict all as positives, we would get 4670 cases estimated as false positives, therefore it would mean 77.7% model accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting power of our Naive bayes model is 83.7%. If we wouldn't use any model and take into account that we have a small number of negative cases in our sample, therefore let's predict all as positive. We would get accuracy of 77.7%. Our model is better about 6%. We cannot consider this result as a success. Let's update our model with following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use a different column such as 'review/text' and test whether productid or userid is relevant. \n",
    "2. In terms of featurewords, use only word that have biggest different between good and bad category.\n",
    "3. Use function collocations that can capture pair of words (see appendix).\n",
    "4. Use sklearn library and class NaiveBayes with bernouli distribution. \n",
    "5. Start with the sample and pick equal number of positive and negative cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations on all words in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Usage of Collocation in practise\n",
    "\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordList)\n",
    "finder.nbest(bigram_measures.pmi, 1000)  # doctest: +NORMALIZE_WHITESPACE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
